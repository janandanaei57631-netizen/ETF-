import streamlit as st
import akshare as ak
import pandas as pd
from openai import OpenAI
from streamlit_autorefresh import st_autorefresh
import concurrent.futures
import datetime
import pytz 

# --- 1. åŸºç¡€é…ç½® ---
st.set_page_config(page_title="AI æ™ºèƒ½ETFåŒ¹é…", layout="wide", initial_sidebar_state="expanded")
st_autorefresh(interval=60000, key="refresh_smart_match_v1")

# CSS æ ·å¼
st.markdown("""
    <style>
        .main { background-color: #0e1117; }
        .news-card { 
            padding: 10px; margin-bottom: 8px; border-radius: 6px; 
            border: 1px solid #333; background-color: #1e1e1e;
        }
        .header-row { display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px; }
        .left-badges { display: flex; align-items: center; gap: 6px; flex-wrap: wrap; }
        
        .time-badge { color: #888; font-family: monospace; font-size: 0.8rem; }
        .src-badge { background: #333; color: #aaa; padding: 1px 4px; border-radius: 3px; font-size: 0.75rem; }
        
        /* ç´«è‰² ETF æ ‡ç­¾ */
        .etf-tag { 
            background: #4a148c; color: #e1bee7; border: 1px solid #7b1fa2; 
            padding: 1px 6px; border-radius: 4px; font-family: monospace; font-weight: bold; 
            font-size: 0.85rem; cursor: pointer; display: flex; align-items: center; gap: 4px;
        }
        /* è“è‰² æ¦‚å¿µæ ‡ç­¾ */
        .sector-tag { background: #0d47a1; color: #90caf9; border: 1px solid #1565c0; padding: 1px 5px; border-radius: 4px; font-size: 0.75rem; }
        /* è°ƒè¯•å°å­— */
        .debug-tag { font-size: 0.7rem; color: #555; margin-left: 5px; font-family: monospace; }

        .impact-high { color: #ff5252; font-weight: bold; margin-left: auto; font-size: 0.85rem; }
        .impact-low { color: #69f0ae; font-weight: bold; margin-left: auto; font-size: 0.85rem; }
        .news-text { color: #ccc; font-size: 0.9rem; line-height: 1.45; }
        
        .col-header-bull { color: #ff5252; border-bottom: 2px solid #ff5252; padding: 8px; text-align: center; font-weight: bold; background: rgba(255, 82, 82, 0.1); border-radius: 4px; margin-bottom: 10px; }
        .col-header-bear { color: #69f0ae; border-bottom: 2px solid #69f0ae; padding: 8px; text-align: center; font-weight: bold; background: rgba(105, 240, 174, 0.1); border-radius: 4px; margin-bottom: 10px; }
    </style>
""", unsafe_allow_html=True)

# --- 2. ä¾§è¾¹æ  ---
if 'watchlist' not in st.session_state:
    st.session_state.watchlist = ["512480", "512690", "512880", "513130", "513050", "159915"]

with st.sidebar:
    st.header("âš¡ ETF äº¤æ˜“å°")
    if "DEEPSEEK_KEY" in st.secrets:
        api_key = st.secrets["DEEPSEEK_KEY"]
        st.success(f"âœ… AI å¼•æ“åœ¨çº¿")
    else:
        api_key = None
        st.error("âŒ å¯†é’¥ç¼ºå¤±")
    
    ai_limit = st.slider("ğŸ¤– åˆ†ææ¡æ•°", 10, 60, 20)
    if st.button("ğŸ”´ å¼ºåˆ¶åˆ·æ–°"):
        st.cache_data.clear()
        st.rerun()

# --- 3. æ ¸å¿ƒï¼šæ™ºèƒ½åŒä¹‰è¯åº“ (åŒå­—èµ·æ­¥) ---
# ç»“æ„ï¼šå…³é”®è¯åˆ—è¡¨ -> (ETFä»£ç , ETFåç§°)
# åªè¦ AI æå–çš„è¯åŒ…å«åˆ—è¡¨é‡Œçš„ä»»æ„ä¸€ä¸ªè¯ï¼Œå°±åŒ¹é…æˆåŠŸ
SMART_MAPPING = {
    # === çƒ­é—¨ç§‘æŠ€ ===
    ("ä½ç©º", "é£è¡Œæ±½è½¦", "æ— äººæœº", "é€šèˆª", "eVTOL", "å†›å·¥", "å›½é˜²", "èˆªå¤©"): ("512660", "å†›å·¥é¾™å¤´"),
    ("æœºå™¨äºº", "è‡ªåŠ¨åŒ–", "å‡é€Ÿå™¨", "äººå‹æœºå™¨äºº", "ä¼ºæœ"): ("159770", "æœºå™¨äººETF"),
    ("AI", "äººå·¥æ™ºèƒ½", "ç®—åŠ›", "æœåŠ¡å™¨", "å…‰æ¨¡å—", "CPO", "å¤§æ¨¡å‹", "è‹±ä¼Ÿè¾¾"): ("159819", "äººå·¥æ™ºèƒ½"),
    ("åŠå¯¼ä½“", "èŠ¯ç‰‡", "é›†æˆç”µè·¯", "æ™¶åœ†", "å…‰åˆ»æœº", "å­˜å‚¨èŠ¯ç‰‡", "ä¸­èŠ¯"): ("512480", "åŠå¯¼ä½“ETF"),
    ("ä¿¡åˆ›", "è½¯ä»¶", "æ“ä½œç³»ç»Ÿ", "ç½‘ç»œå®‰å…¨", "è®¡ç®—æœº", "äº‘è®¡ç®—", "å¤§æ•°æ®"): ("512720", "è®¡ç®—æœºETF"),
    ("æ¸¸æˆ", "ç”µç«", "ç½‘æ¸¸", "æ‰‹æ¸¸"): ("159869", "æ¸¸æˆETF"),
    ("ä¼ åª’", "çŸ­å‰§", "å½±è§†", "é™¢çº¿", "å…ƒå®‡å®™"): ("512980", "ä¼ åª’ETF"),
    ("æ¶ˆè´¹ç”µå­", "è‹¹æœäº§ä¸šé“¾", "æœé“¾", "æ™ºèƒ½æ‰‹æœº", "åä¸ºæ‰‹æœº", "ç«‹è®¯"): ("159732", "æ¶ˆç”µETF"),
    ("é€šä¿¡", "5G", "6G", "è¿è¥å•†", "ä¸­å›½ç§»åŠ¨"): ("515880", "é€šä¿¡ETF"),
    
    # === æ–°èƒ½æº/é«˜ç«¯åˆ¶é€  ===
    ("æ±½è½¦", "æ•´è½¦", "ä¹˜ç”¨è½¦", "è‡ªåŠ¨é©¾é©¶", "æ— äººé©¾é©¶", "æ™ºèƒ½é©¾é©¶"): ("516110", "æ±½è½¦ETF"),
    ("ç”µæ± ", "é”‚ç”µ", "å›ºæ€ç”µæ± ", "åŠ¨åŠ›ç”µæ± ", "å‚¨èƒ½", "å®å¾·æ—¶ä»£"): ("159755", "ç”µæ± ETF"),
    ("å…‰ä¼", "å¤ªé˜³èƒ½", "ç¡…æ–™", "ç»„ä»¶", "é€†å˜å™¨", "éš†åŸº"): ("515790", "å…‰ä¼ETF"),
    ("æ–°èƒ½æº", "æ–°èƒ½è½¦", "ç”µåŠ¨è½¦"): ("516160", "æ–°èƒ½æºETF"),

    # === èµ„æº/å‘¨æœŸ/çº¢åˆ© ===
    ("é»„é‡‘", "è´µé‡‘å±", "é‡‘ä»·"): ("518880", "é»„é‡‘ETF"),
    ("æœ‰è‰²", "é“œçŸ¿", "é“ä¸š", "ç¨€åœŸ", "ç´«é‡‘çŸ¿ä¸š"): ("512400", "æœ‰è‰²ETF"),
    ("çŸ³æ²¹", "åŸæ²¹", "çŸ³åŒ–", "æ²¹æ°”", "ä¸‰æ¡¶æ²¹"): ("561360", "çŸ³æ²¹ETF"),
    ("ç…¤ç‚­", "åŠ¨åŠ›ç…¤", "ç„¦ç…¤", "ç¥å"): ("515220", "ç…¤ç‚­ETF"),
    ("ç”µåŠ›", "ç»¿ç”µ", "ç«ç”µ", "æ ¸ç”µ", "ç”µç½‘"): ("561560", "ç”µåŠ›ETF"),
    ("çº¢åˆ©", "é«˜è‚¡æ¯", "ä¸­å­—å¤´", "å›½ä¼æ”¹é©", "å¤®ä¼"): ("510880", "çº¢åˆ©ETF"),
    ("èˆªè¿", "æµ·è¿", "æ¸¯å£", "é›†è¿", "ä¸­è¿œæµ·æ§"): ("510880", "çº¢åˆ©ETF"), # å½’å…¥çº¢åˆ©æˆ–äº¤è¿

    # === æ¶ˆè´¹/åŒ»è¯ ===
    ("ç™½é…’", "é«˜ç«¯é…’", "èŒ…å°", "äº”ç²®æ¶²"): ("512690", "é…’ETF"),
    ("é£Ÿå“", "é¥®æ–™", "ä¹³ä¸š", "è°ƒå‘³å“", "é›¶é£Ÿ"): ("512690", "é…’ETF"),
    ("çŒªè‚‰", "å…»æ®–", "ç”ŸçŒª", "é¥²æ–™", "å†œä¸š"): ("516760", "å…»æ®–ETF"),
    ("åŒ»è¯", "åˆ›æ–°è¯", "ç–«è‹—", "CXO", "æ’ç‘"): ("512010", "åŒ»è¯ETF"),
    ("åŒ»ç–—", "åŒ»ç–—å™¨æ¢°", "åŒ»ç¾", "çœ¼ç§‘", "ç‰™ç§‘"): ("512170", "åŒ»ç–—ETF"),
    ("ä¸­è¯", "ä¸­æˆè¯"): ("560080", "ä¸­è¯ETF"),
    ("å®¶ç”µ", "ç™½è‰²å®¶ç”µ", "ç©ºè°ƒ", "å†°ç®±"): ("159996", "å®¶ç”µETF"),
    ("æ—…æ¸¸", "å…ç¨", "é…’åº—", "èˆªç©º", "æœºåœº"): ("562510", "æ—…æ¸¸ETF"),

    # === é‡‘è/åœ°äº§ ===
    ("è¯åˆ¸", "åˆ¸å•†", "æŠ•è¡Œ", "ç‰›å¸‚æ——æ‰‹"): ("512880", "è¯åˆ¸ETF"),
    ("é“¶è¡Œ", "å››å¤§è¡Œ"): ("512800", "é“¶è¡ŒETF"),
    ("ä¿é™©", "å¯¿é™©", "è´¢é™©"): ("512070", "ä¿é™©ETF"),
    ("æˆ¿åœ°äº§", "åœ°äº§", "æ¥¼å¸‚", "ä¸‡ç§‘", "ä¿åˆ©"): ("512200", "åœ°äº§ETF"),

    # === å®½åŸº/æµ·å¤– ===
    ("çº³æŒ‡", "çº³æ–¯è¾¾å…‹", "ç¾è‚¡", "æ ‡æ™®", "ç‰¹æ–¯æ‹‰", "å¾®è½¯"): ("513100", "çº³æŒ‡ETF"),
    ("æ¸¯è‚¡", "æ’ç”Ÿ", "æ¸¯è‚¡é€š", "è…¾è®¯", "ç¾å›¢", "é˜¿é‡Œ"): ("513130", "æ’ç”Ÿç§‘æŠ€"),
    ("ç§‘åˆ›æ¿", "ç§‘åˆ›50"): ("588000", "ç§‘åˆ›50"),
    ("åˆ›ä¸šæ¿", "åˆ›50"): ("159915", "åˆ›ä¸šæ¿"),
    ("æ²ªæ·±300", "å¤§ç›˜è‚¡"): ("510300", "æ²ªæ·±300"),
    ("ä¸­è¯500", "ä¸­ç›˜è‚¡"): ("510500", "ä¸­è¯500"),
    ("ä¸­è¯1000", "å¾®ç›˜è‚¡"): ("512100", "ä¸­è¯1000")
}

def smart_map_to_etf(ai_keyword):
    """
    æ™ºèƒ½åŒ¹é…é€»è¾‘ (æ‹’ç»å•å­—ï¼Œæœ€é•¿åŒ¹é…ä¼˜å…ˆ)
    """
    if not ai_keyword or ai_keyword == "æ— ": return None
    
    # æ‰å¹³åŒ–å­—å…¸ï¼Œæ–¹ä¾¿å¤„ç†
    # key_list = [("é£è¡Œæ±½è½¦", "512660", "å†›å·¥é¾™å¤´"), ("ä½ç©º", "512660", "å†›å·¥é¾™å¤´")...]
    flat_mapping = []
    for keywords, (code, name) in SMART_MAPPING.items():
        for k in keywords:
            flat_mapping.append((k, code, name))
    
    # æ ¸å¿ƒç®—æ³•ï¼šæŒ‰å…³é”®è¯é•¿åº¦é™åºæ’åˆ— (æœ€é•¿è¯ä¼˜å…ˆ)
    # è¿™æ · "æ–°èƒ½æºæ±½è½¦" ä¼šå…ˆäº "æ±½è½¦" è¢«åŒ¹é…
    flat_mapping.sort(key=lambda x: len(x[0]), reverse=True)
    
    for key, code, name in flat_mapping:
        # 1. è¿‡æ»¤æ‰å•å­— (åŒé‡ä¿é™©)
        if len(key) < 2: continue
        
        # 2. åŒ…å«åŒ¹é…
        # å¦‚æœ å­—å…¸é‡Œçš„è¯ (key) å‡ºç°åœ¨ AIæå–çš„è¯ (ai_keyword) é‡Œ
        if key in ai_keyword:
            return code, name
            
        # 3. åå‘åŒ…å« (å®¹é”™)
        # å¦‚æœ AIæå–çš„è¯ å¾ˆçŸ­ï¼Œåˆšå¥½åŒ…å«åœ¨ å­—å…¸é•¿è¯ é‡Œ (è¿™ç§æƒ…å†µè¾ƒå°‘ï¼Œä½†ä¸ºäº†ä¿é™©)
        if len(ai_keyword) >= 2 and ai_keyword in key:
            return code, name
            
    return None, None

# --- 4. AI åˆ†æ ---
def analyze_news(content):
    if not api_key: return None
    try:
        client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
        # Prompt å‡çº§ï¼šè¦æ±‚æå–å…·ä½“è¡Œä¸š
        prompt = f"""
        åˆ†ææ–°é—»ï¼š{content[:150]}
        è¯·è¾“å‡ºï¼šæ–¹å‘|æ ¸å¿ƒèµ›é“|å¼ºåº¦
        
        1.æ–¹å‘ï¼šåˆ©å¥½/åˆ©ç©º/ä¸­æ€§
        2.æ ¸å¿ƒèµ›é“ï¼š
           - æå–æœ€å…·ä½“çš„ã€è¡Œä¸šæˆ–æ¿å—å…¨ç§°ã€‘ã€‚
           - ä¸è¦ç”¨å•å­—ï¼ˆä¸è¦å†™"è½¦"ï¼Œè¦å†™"æ±½è½¦"æˆ–"æ–°èƒ½æºè½¦"ï¼‰ã€‚
           - ä¸è¦å†™ä»£ç ã€‚
           - ä¸¾ä¾‹ï¼šä½ç©ºç»æµã€å…‰ä¼ç»„ä»¶ã€ç™½é…’ã€æ¶ˆè´¹ç”µå­ã€äººå·¥æ™ºèƒ½ã€‚
        3.å¼ºåº¦ï¼šæš´æ¶¨/å¤§æ¶¨/å¾®æ¶¨/æš´è·Œ/å¤§è·Œ/å¾®è·Œ/æ— 
        
        ç¤ºä¾‹ï¼šåˆ©å¥½|ä½ç©ºç»æµ|å¤§æ¶¨
        """
        res = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1, max_tokens=50
        )
        parts = res.choices[0].message.content.strip().split('|')
        if len(parts) >= 3:
            concept = parts[1].strip()
            # æ™ºèƒ½åŒ¹é…
            code, name = smart_map_to_etf(concept)
            
            return {
                "dir": parts[0].strip(),
                "concept": concept,
                "etf_code": code,
                "etf_name": name,
                "impact": parts[2].strip()
            }
        return None
    except: return None

# --- 5. æ•°æ®è·å– ---
def clean_date(t_str):
    try:
        if len(str(t_str)) > 16: return str(t_str)[5:16]
        return str(t_str)
    except: return ""

@st.cache_data(ttl=60)
def get_data_smart(limit):
    news = []
    try:
        df1 = ak.stock_info_global_sina()
        for _, r in df1.iterrows(): news.append({"t": str(r['æ—¶é—´']), "txt": str(r['å†…å®¹']), "src": "æ–°æµª"})
    except: pass
    
    try:
        df2 = ak.stock_news_em(symbol="å…¨éƒ¨").head(300)
        for _, r in df2.iterrows(): news.append({"t": str(r['å‘å¸ƒæ—¶é—´']), "txt": str(r['æ–°é—»æ ‡é¢˜']), "src": "ä¸œè´¢"})
    except: pass
    
    try:
        df3 = ak.stock_info_global_cls(symbol="å…¨éƒ¨")
        for _, r in df3.iterrows(): news.append({"t": str(r['å‘å¸ƒæ—¶é—´']), "txt": str(r['å†…å®¹']), "src": "è´¢è”"})
    except: pass

    df = pd.DataFrame(news)
    if df.empty: return df
    
    df.drop_duplicates(subset=['txt'], inplace=True)
    df = df.head(limit + 50) 

    df_head = df.head(limit).copy()
    df_tail = df.iloc[limit:].copy()
    df_tail['ai'] = None

    if not df_head.empty:
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            results = list(executor.map(analyze_news, df_head['txt'].tolist()))
        df_head['ai'] = results
    
    return pd.concat([df_head, df_tail])

# --- 6. æ¸²æŸ“å¡ç‰‡ ---
def render_card(row):
    ai = row['ai']
    tags = ""
    
    if ai:
        code = ai.get('etf_code')
        name = ai.get('etf_name')
        concept = ai.get('concept', 'æœªçŸ¥')
        
        if code:
            # å‘½ä¸­å­—å…¸
            tags += f"<span class='etf-tag'>ğŸ“Š {name} {code}</span> "
            tags += f"<span class='debug-tag'>[AI:{concept}]</span>"
        elif concept and concept != "æ— ":
            # æœªå‘½ä¸­
            tags += f"<span class='sector-tag'>ğŸ“‚ {concept}</span> "
            tags += f"<span class='debug-tag'>[æœªåŒ¹é…]</span>"
            
        imp = ai.get('impact', '')
        if "æ¶¨" in imp: tags += f"<span class='impact-high'>ğŸ”¥ {imp}</span>"
        elif "è·Œ" in imp: tags += f"<span class='impact-low'>ğŸŸ¢ {imp}</span>"
    
    st.markdown(
        f"""
        <div class="news-card">
            <div class="header-row">
                <div class="left-badges">
                    <span class="time-badge">{clean_date(row['t'])}</span>
                    <span class="src-badge">{row['src']}</span>
                    {tags}
                </div>
            </div>
            <div class="news-text">{row['txt']}</div>
        </div>
        """, unsafe_allow_html=True
    )

# --- 7. ä¸»ç•Œé¢ ---
col1, col2 = st.columns([3, 1])

with col1:
    with st.spinner("ğŸš€ AI æ­£åœ¨è¿›è¡Œæ™ºèƒ½è¯­ä¹‰åŒ¹é…..."):
        df = get_data_smart(ai_limit)
    
    if not df.empty:
        df_ai = df[df['ai'].notnull()]
        
        bull = df_ai[df_ai['ai'].apply(lambda x: x and 'åˆ©å¥½' in x.get('dir', ''))]
        bear = df_ai[df_ai['ai'].apply(lambda x: x and 'åˆ©ç©º' in x.get('dir', ''))]
        
        exclude = list(bull.index) + list(bear.index)
        rest = df[~df.index.isin(exclude)]
        
        c_bull, c_bear = st.columns(2)
        with c_bull:
            st.markdown(f"<div class='col-header-bull'>ğŸ”¥ åˆ©å¥½ ({len(bull)})</div>", unsafe_allow_html=True)
            if not bull.empty:
                for _, r in bull.iterrows(): render_card(r)
            else: st.info("æš‚æ— ä¿¡å·")
            
        with c_bear:
            st.markdown(f"<div class='col-header-bear'>ğŸŸ¢ åˆ©ç©º ({len(bear)})</div>", unsafe_allow_html=True)
            if not bear.empty:
                for _, r in bear.iterrows(): render_card(r)
            else: st.info("æš‚æ— ä¿¡å·")
            
        st.markdown("---")
        st.caption(f"ğŸ“œ å¸‚åœºå™ªéŸ³ ({len(rest)})")
        with st.container(height=400):
            for _, r in rest.iterrows():
                st.text(f"{clean_date(r['t'])} | {r['txt']}")
    else:
        st.error("æš‚æ— æ•°æ®")

with col2:
    st.subheader("ğŸ“Š è‡ªé€‰ ETF")
    try:
        codes = st.session_state.watchlist
        spot = ak.fund_etf_spot_em()
        my_spot = spot[spot['ä»£ç '].isin(codes)]
        for _, r in my_spot.iterrows():
            val = float(r['æ¶¨è·Œå¹…'])
            c = "red" if val > 0 else "green"
            st.markdown(f"**{r['åç§°']}** `{r['ä»£ç ']}` : <span style='color:{c}'>{val}%</span>", unsafe_allow_html=True)
            st.divider()
    except: st.caption("è¡Œæƒ…åŠ è½½ä¸­...")
