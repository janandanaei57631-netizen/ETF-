import streamlit as st
import akshare as ak
import pandas as pd
from openai import OpenAI
from streamlit_autorefresh import st_autorefresh
import concurrent.futures
import datetime
import pytz 

# --- 1. åŸºç¡€é…ç½® ---
st.set_page_config(page_title="AI ETF ç‹™å‡»æ‰‹", layout="wide", initial_sidebar_state="expanded")
st_autorefresh(interval=60000, key="refresh_etf_sniper_v1")

# CSS æ ·å¼ (é…è‰²ä¼˜åŒ–ï¼šETF ä¸“å±ç´«è‰²æ ‡ç­¾)
st.markdown("""
    <style>
        .main { background-color: #0e1117; }
        .news-card { 
            padding: 10px; margin-bottom: 8px; border-radius: 6px; 
            border: 1px solid #333; background-color: #1e1e1e;
        }
        .header-row { display: flex; justify-content: space-between; align-items: center; margin-bottom: 5px; }
        .left-badges { display: flex; align-items: center; gap: 6px; flex-wrap: wrap; }
        
        .time-badge { color: #888; font-family: monospace; font-size: 0.8rem; }
        .src-badge { background: #333; color: #aaa; padding: 1px 4px; border-radius: 3px; font-size: 0.75rem; }
        
        /* ETF ä¸“å±æ ‡ç­¾æ ·å¼ */
        .etf-tag { 
            background: #4a148c; color: #e1bee7; border: 1px solid #7b1fa2; 
            padding: 1px 6px; border-radius: 4px; font-family: monospace; font-weight: bold; 
            font-size: 0.85rem; cursor: pointer; display: flex; align-items: center; gap: 4px;
        }
        
        .sector-tag { background: #0d47a1; color: #90caf9; border: 1px solid #1565c0; padding: 1px 5px; border-radius: 4px; font-size: 0.75rem; }
        
        .impact-high { color: #ff5252; font-weight: bold; margin-left: auto; font-size: 0.85rem; }
        .impact-low { color: #69f0ae; font-weight: bold; margin-left: auto; font-size: 0.85rem; }
        
        .news-text { color: #ccc; font-size: 0.9rem; line-height: 1.45; }
        
        .col-header-bull { color: #ff5252; border-bottom: 2px solid #ff5252; padding: 8px; text-align: center; font-weight: bold; background: rgba(255, 82, 82, 0.1); border-radius: 4px; margin-bottom: 10px; }
        .col-header-bear { color: #69f0ae; border-bottom: 2px solid #69f0ae; padding: 8px; text-align: center; font-weight: bold; background: rgba(105, 240, 174, 0.1); border-radius: 4px; margin-bottom: 10px; }
    </style>
""", unsafe_allow_html=True)

# --- 2. ä¾§è¾¹æ  ---
# é»˜è®¤è‡ªé€‰è‚¡æ”¹æˆ ETF
if 'watchlist' not in st.session_state:
    st.session_state.watchlist = ["512480", "512690", "512880", "513130", "513050", "159915"]

with st.sidebar:
    st.header("âš¡ ETF äº¤æ˜“å°")
    if "DEEPSEEK_KEY" in st.secrets:
        api_key = st.secrets["DEEPSEEK_KEY"]
        st.success(f"âœ… AI å¼•æ“åœ¨çº¿")
    else:
        api_key = None
        st.error("âŒ å¯†é’¥ç¼ºå¤±")
    
    ai_limit = st.slider("ğŸ¤– åˆ†ææ¡æ•°", 10, 60, 20)
    
    if st.button("ğŸ”´ å¼ºåˆ¶åˆ·æ–°"):
        st.cache_data.clear()
        st.rerun()

# --- 3. æ ¸å¿ƒï¼šä¸‡ç‰©æ˜ å°„ ETF å­—å…¸ ---
# è¿™æ˜¯ä¸€ä¸ªåºå¤§çš„æ˜ å°„è¡¨ï¼ŒæŠŠä¸ªè‚¡å’Œæ¦‚å¿µéƒ½æ˜ å°„åˆ° ETF
ETF_MAPPING = {
    # --- ç§‘æŠ€/åŠå¯¼ä½“ ---
    "åŠå¯¼ä½“": "512480", "èŠ¯ç‰‡": "512480", "ä¸­èŠ¯å›½é™…": "512480", "åŒ—æ–¹ååˆ›": "512480", "æµ·å…‰ä¿¡æ¯": "512480", "å¯’æ­¦çºª": "512480",
    "äººå·¥æ™ºèƒ½": "159819", "AI": "159819", "ç®—åŠ›": "159819", "CPO": "159819", "ç§‘å¤§è®¯é£": "159819", "ä¸‰å…­é›¶": "159819",
    "è®¡ç®—æœº": "512720", "è½¯ä»¶": "512720", "ä¿¡åˆ›": "512720", "é‡‘å±±åŠå…¬": "512720",
    "æ¸¸æˆ": "159869", "ä¼ åª’": "512980", "ç¥å·æ³°å²³": "159869", "æ˜†ä»‘ä¸‡ç»´": "512980",
    "æ¶ˆè´¹ç”µå­": "159732", "ç«‹è®¯ç²¾å¯†": "159732", "æ­Œå°”": "159732",

    # --- æ–°èƒ½æº/è½¦ ---
    "æ–°èƒ½æº": "516160", "å…‰ä¼": "515790", "éš†åŸº": "515790", "é€šå¨": "515790", "é˜³å…‰ç”µæº": "515790",
    "ç”µæ± ": "159755", "é”‚ç”µ": "159755", "å®å¾·æ—¶ä»£": "159755", "å®å¾·": "159755", "äº¿çº¬é”‚èƒ½": "159755",
    "æ±½è½¦": "516110", "æ¯”äºšè¿ª": "516110", "é•¿å®‰æ±½è½¦": "516110", "èµ›åŠ›æ–¯": "516110",

    # --- æ¶ˆè´¹/åŒ»è¯ ---
    "ç™½é…’": "512690", "é£Ÿå“": "512690", "æ¶ˆè´¹": "159928", "è´µå·èŒ…å°": "512690", "èŒ…å°": "512690", "äº”ç²®æ¶²": "512690", "æ³¸å·è€çª–": "512690",
    "åŒ»è¯": "512010", "åŒ»ç–—": "512170", "CXO": "512170", "æ’ç‘åŒ»è¯": "512010", "è¯æ˜åº·å¾·": "512170", "è¿ˆç‘åŒ»ç–—": "512170",
    "ä¸­è¯": "560080", "ç‰‡ä»”ç™€": "560080",

    # --- é‡‘è/åœ°äº§ ---
    "è¯åˆ¸": "512880", "åˆ¸å•†": "512880", "ä¸­ä¿¡è¯åˆ¸": "512880", "ä¸œæ–¹è´¢å¯Œ": "512880", "å…‰å¤§è¯åˆ¸": "512880",
    "é“¶è¡Œ": "512800", "æ‹›å•†é“¶è¡Œ": "512800", "å·¥å•†é“¶è¡Œ": "512800",
    "ä¿é™©": "512070", "ä¸­å›½å¹³å®‰": "512070",
    "æˆ¿åœ°äº§": "512200", "åœ°äº§": "512200", "ä¸‡ç§‘": "512200", "ä¿åˆ©": "512200",

    # --- è·¨å¢ƒ/å®½åŸº/èµ„æº ---
    "ç¾è‚¡": "513100", "çº³æŒ‡": "513100", "è‹±ä¼Ÿè¾¾": "513100", "ç‰¹æ–¯æ‹‰": "513100", "è‹¹æœ": "513100", "å¾®è½¯": "513100",
    "æ¸¯è‚¡": "513130", "æ’ç”Ÿç§‘æŠ€": "513130", "è…¾è®¯": "513130", "é˜¿é‡Œå·´å·´": "513130", "ç¾å›¢": "513130", "å¿«æ‰‹": "513130",
    "ä¸­æ¦‚": "513050", "æ‹¼å¤šå¤š": "513050",
    "é»„é‡‘": "518880", "ç´«é‡‘çŸ¿ä¸š": "518880", "æœ‰è‰²": "512400", "é“œ": "512400",
    "æ²ªæ·±300": "510300", "ç§‘åˆ›50": "588000", "åˆ›ä¸šæ¿": "159915"
}

def map_to_etf(keyword):
    """
    è¾“å…¥ï¼šæ–°é—»ä¸»ä½“ï¼ˆå¦‚'èŒ…å°'ï¼‰
    è¾“å‡ºï¼šETFä»£ç å’Œåç§°ï¼ˆå¦‚ '512690'ï¼‰
    """
    if not keyword or keyword == "æ— ": return None
    
    # 1. ç›´æ¥åŒ¹é…
    if keyword in ETF_MAPPING: return ETF_MAPPING[keyword]
    
    # 2. æ¨¡ç³ŠåŒ¹é… (æ¯”å¦‚ AI æå–äº† 'è´µå·èŒ…å°é…’', å­—å…¸é‡Œæœ‰ 'è´µå·èŒ…å°')
    for k, v in ETF_MAPPING.items():
        if k in keyword: return v
        if keyword in k: return v # åå‘åŒ¹é…
    
    return None

# --- 4. AI åˆ†æ ---
def analyze_news(content):
    if not api_key: return None
    try:
        client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
        # Prompt ä¿®æ”¹ï¼šè®© AI æå–â€œæœ€æ ¸å¿ƒçš„æ¦‚å¿µâ€
        prompt = f"""
        åˆ†ææ–°é—»ï¼š{content[:150]}
        è¯·è¾“å‡ºï¼šæ–¹å‘|æ ¸å¿ƒæ¦‚å¿µ|å¼ºåº¦
        
        1.æ–¹å‘ï¼šåˆ©å¥½/åˆ©ç©º/ä¸­æ€§
        2.æ ¸å¿ƒæ¦‚å¿µï¼šæå–æœ€ç›¸å…³çš„ã€è¡Œä¸šåã€‘æˆ–ã€é¾™å¤´å…¬å¸åã€‘ã€‚
          - å°½é‡ç”¨é€šç”¨è¯ï¼Œå¦‚"ç™½é…’"ã€"å…‰ä¼"ã€"è‹±ä¼Ÿè¾¾"ã€"ä¸­ä¿¡è¯åˆ¸"ã€‚
          - ä¸è¦å†™ä»£ç ã€‚
        3.å¼ºåº¦ï¼šæš´æ¶¨/å¤§æ¶¨/å¾®æ¶¨/æš´è·Œ/å¤§è·Œ/å¾®è·Œ/æ— 
        
        ç¤ºä¾‹ï¼šåˆ©å¥½|ç™½é…’|å¤§æ¶¨
        """
        res = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1, max_tokens=50
        )
        parts = res.choices[0].message.content.strip().split('|')
        if len(parts) >= 3:
            concept = parts[1].strip()
            # æ˜ å°„åˆ° ETF
            etf_code = map_to_etf(concept)
            
            return {
                "dir": parts[0].strip(),
                "concept": concept,
                "etf": etf_code,
                "impact": parts[2].strip()
            }
        return None
    except: return None

# --- 5. æ•°æ®è·å– ---
def clean_date(t_str):
    try:
        if len(str(t_str)) > 16: return str(t_str)[5:16]
        return str(t_str)
    except: return ""

@st.cache_data(ttl=60)
def get_data(limit):
    news = []
    # æé€Ÿå¤šæº
    try:
        df1 = ak.stock_info_global_sina()
        for _, r in df1.iterrows(): news.append({"t": str(r['æ—¶é—´']), "txt": str(r['å†…å®¹']), "src": "æ–°æµª"})
    except: pass
    
    try:
        df2 = ak.stock_news_em(symbol="å…¨éƒ¨").head(300)
        for _, r in df2.iterrows(): news.append({"t": str(r['å‘å¸ƒæ—¶é—´']), "txt": str(r['æ–°é—»æ ‡é¢˜']), "src": "ä¸œè´¢"})
    except: pass
    
    try:
        df3 = ak.stock_info_global_cls(symbol="å…¨éƒ¨")
        for _, r in df3.iterrows(): news.append({"t": str(r['å‘å¸ƒæ—¶é—´']), "txt": str(r['å†…å®¹']), "src": "è´¢è”"})
    except: pass

    df = pd.DataFrame(news)
    if df.empty: return df
    
    df.drop_duplicates(subset=['txt'], inplace=True)
    df = df.head(limit + 50) 

    df_head = df.head(limit).copy()
    df_tail = df.iloc[limit:].copy()
    df_tail['ai'] = None

    if not df_head.empty:
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            results = list(executor.map(analyze_news, df_head['txt'].tolist()))
        df_head['ai'] = results
    
    return pd.concat([df_head, df_tail])

# --- 6. æ¸²æŸ“å¡ç‰‡ ---
def render_card(row):
    ai = row['ai']
    tags = ""
    
    if ai:
        # æ˜¾ç¤º ETF æ ‡ç­¾
        if ai['etf']:
            # æ˜¾ç¤ºä¸ºï¼š[ETFå›¾æ ‡] æ¦‚å¿µå ä»£ç 
            tags += f"<span class='etf-tag'>ğŸ“Š {ai['concept']} {ai['etf']}</span> "
        elif ai['concept'] and ai['concept'] != "æ— ":
            # æ²¡åŒ¹é…åˆ° ETFï¼Œæ˜¾ç¤ºè“è‰²æ¦‚å¿µæ ‡ç­¾
            tags += f"<span class='sector-tag'>{ai['concept']}</span> "
            
        imp = ai['impact']
        if "æ¶¨" in imp: tags += f"<span class='impact-high'>ğŸ”¥ {imp}</span>"
        elif "è·Œ" in imp: tags += f"<span class='impact-low'>ğŸŸ¢ {imp}</span>"
    
    st.markdown(
        f"""
        <div class="news-card">
            <div class="header-row">
                <div class="left-badges">
                    <span class="time-badge">{clean_date(row['t'])}</span>
                    <span class="src-badge">{row['src']}</span>
                    {tags}
                </div>
            </div>
            <div class="news-text">{row['txt']}</div>
        </div>
        """, unsafe_allow_html=True
    )

# --- 7. ä¸»ç•Œé¢ ---
col1, col2 = st.columns([3, 1])

with col1:
    with st.spinner("ğŸš€ AI æ­£åœ¨å°†æ–°é—»æ˜ å°„åˆ° ETF ç­–ç•¥..."):
        df = get_data(ai_limit)
    
    if not df.empty:
        df_ai = df[df['ai'].notnull()]
        
        bull = df_ai[df_ai['ai'].apply(lambda x: x and 'åˆ©å¥½' in x['dir'])]
        bear = df_ai[df_ai['ai'].apply(lambda x: x and 'åˆ©ç©º' in x['dir'])]
        
        exclude = list(bull.index) + list(bear.index)
        rest = df[~df.index.isin(exclude)]
        
        c_bull, c_bear = st.columns(2)
        with c_bull:
            st.markdown(f"<div class='col-header-bull'>ğŸ”¥ åˆ©å¥½ ETF ({len(bull)})</div>", unsafe_allow_html=True)
            if not bull.empty:
                for _, r in bull.iterrows(): render_card(r)
            else: st.info("æš‚æ— ä¿¡å·")
            
        with c_bear:
            st.markdown(f"<div class='col-header-bear'>ğŸŸ¢ åˆ©ç©º ETF ({len(bear)})</div>", unsafe_allow_html=True)
            if not bear.empty:
                for _, r in bear.iterrows(): render_card(r)
            else: st.info("æš‚æ— ä¿¡å·")
            
        st.markdown("---")
        st.caption(f"ğŸ“œ å¸‚åœºå™ªéŸ³ ({len(rest)})")
        with st.container(height=400):
            for _, r in rest.iterrows():
                st.text(f"{clean_date(r['t'])} | {r['txt']}")
    else:
        st.error("æš‚æ— æ•°æ®")

with col2:
    st.subheader("ğŸ“Š è‡ªé€‰ ETF")
    try:
        codes = st.session_state.watchlist
        spot = ak.fund_etf_spot_em()
        my_spot = spot[spot['ä»£ç '].isin(codes)]
        for _, r in my_spot.iterrows():
            val = float(r['æ¶¨è·Œå¹…'])
            c = "red" if val > 0 else "green"
            st.markdown(f"**{r['åç§°']}** `{r['ä»£ç ']}` : <span style='color:{c}'>{val}%</span>", unsafe_allow_html=True)
            st.divider()
    except: st.caption("è¡Œæƒ…è¿æ¥ä¸­...")
