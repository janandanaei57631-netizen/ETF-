import streamlit as st
import akshare as ak
import pandas as pd
from openai import OpenAI
from streamlit_autorefresh import st_autorefresh
from datetime import datetime

# --- 1. åŸºç¡€é…ç½® ---
st.set_page_config(page_title="AI å…¨è‡ªåŠ¨æŠ•ç ” (çº¢æ¶¨ç»¿è·Œ)", layout="wide")
# è‡ªåŠ¨åˆ·æ–°é¢‘ç‡è®¾ä¸º 3 åˆ†é’Ÿ (180000æ¯«ç§’)ï¼Œå› ä¸ºå…¨è‡ªåŠ¨åˆ†ææ¯”è¾ƒè€—æ—¶ï¼Œåˆ·å¤ªå¿«ä¼šçœ‹ä¸å®Œ
st_autorefresh(interval=180000, key="data_refresh")

# é…ç½® DeepSeek Key
try:
    if "DEEPSEEK_KEY" in st.secrets:
        client = OpenAI(api_key=st.secrets["DEEPSEEK_KEY"], base_url="https://api.deepseek.com")
    else:
        client = None
except:
    client = None

# --- 2. ä½ çš„è‡ªé€‰ ETF æ±  ---
MY_POOL = {
    "518880": "é»„é‡‘ETF",
    "512480": "åŠå¯¼ä½“ETF",
    "513130": "æ’ç”Ÿç§‘æŠ€",
    "513050": "ä¸­æ¦‚äº’è”",
    "159915": "åˆ›ä¸šæ¿",
    "510300": "æ²ªæ·±300",
    "515790": "å…‰ä¼ETF",
    "512690": "é…’ETF",
    "512010": "åŒ»è¯ETF",
    "513500": "æ ‡æ™®500",
    "513330": "æ’ç”Ÿäº’è”ç½‘"
}

# --- 3. AI åˆ†æå¤§è„‘ (æç®€è¾“å‡ºç‰ˆ) ---
def analyze_news_automatically(content):
    if not client: return "âŒ æœªé…ç½® Key"
    
    prompt = f"""
    åˆ†ææ–°é—»ï¼š{content}
    è¯·ä»ä»¥ä¸‹ETFæ± ä¸­ï¼š{list(MY_POOL.keys())} {list(MY_POOL.values())}ï¼Œé€‰å‡ºå—å½±å“æœ€å¤§çš„1ä¸ªã€‚
    
    æ ¼å¼è¦æ±‚ï¼ˆä¸¥ç¦åºŸè¯ï¼‰ï¼š
    ã€æ–¹å‘ã€‘åˆ©å¥½/åˆ©ç©º/ä¸­æ€§
    ã€æ ‡çš„ã€‘ä»£ç  (åç§°)
    ã€é€»è¾‘ã€‘15å­—ä»¥å†…çŸ­å¥
    """
    try:
        res = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=100 # é™åˆ¶è¾“å‡ºé•¿åº¦ï¼Œæé«˜é€Ÿåº¦
        )
        return res.choices[0].message.content
    except:
        return "AI åˆ†æè¶…æ—¶"

# --- 4. è¶…çº§æ–°é—»èšåˆå™¨ (å›½å†…+å›½å¤–) ---
@st.cache_data(ttl=180) # 3åˆ†é’Ÿç¼“å­˜
def get_merged_news():
    news_list = []
    
    # æº1ï¼šè´¢è”ç¤¾ (å›½å†…Aè‚¡ä¸ºä¸»)
    try:
        df_cn = ak.stock_info_global_cls(symbol="å…¨éƒ¨").head(15)
        # ç»Ÿä¸€æ ¼å¼
        for _, row in df_cn.iterrows():
            # è´¢è”ç¤¾çš„æ—¶é—´é€šå¸¸æ˜¯ä¸å¸¦æ—¥æœŸçš„ï¼Œéœ€è¦å¤„ç†ä¸€ä¸‹æˆ–è€…ç›´æ¥ç”¨
            news_list.append({
                "time": str(row['å‘å¸ƒæ—¶é—´']), 
                "content": row['å†…å®¹'],
                "source": "ğŸ‡¨ğŸ‡³ å›½å†…"
            })
    except:
        pass

    # æº2ï¼šé‡‘åæ•°æ® (å›½é™…/å®è§‚/é»„é‡‘/ç¾è‚¡)
    try:
        df_global = ak.js_news(count=15)
        for _, row in df_global.iterrows():
            news_list.append({
                "time": str(row['time']), 
                "content": row['title'], # é‡‘åçš„å†…å®¹åœ¨titleå­—æ®µ
                "source": "ğŸŒ å…¨çƒ"
            })
    except:
        pass
    
    # è½¬ä¸º DataFrame å¹¶æŒ‰æ—¶é—´æ’åº (ç®€å•çš„å­—ç¬¦ä¸²æ’åºï¼Œè¦æ±‚æ ¼å¼å¤§æ¦‚ä¸€è‡´)
    final_df = pd.DataFrame(news_list)
    if not final_df.empty:
        # ç®€å•å»é‡
        final_df.drop_duplicates(subset=['content'], inplace=True)
        # å–å‰ 10 æ¡æ˜¾ç¤º
        return final_df.head(10)
    return pd.DataFrame()

# --- 5. é¡µé¢å¸ƒå±€ ---
st.title("ğŸ¤– AI å…¨è‡ªåŠ¨ç›¯ç›˜ç³»ç»Ÿ")
st.caption("ğŸ”´ çº¢è‰²=æ¶¨ | ğŸŸ¢ ç»¿è‰²=è·Œ | AI è‡ªåŠ¨è§£è¯»å‰ 8 æ¡æœ€æ–°æƒ…æŠ¥")

col1, col2 = st.columns([2, 1])

# åŠ è½½æ•°æ®
with st.spinner("æ­£åœ¨èšåˆå…¨çƒæ–°é—»å¹¶è¿›è¡Œ AI åˆ†æ..."):
    news_df = get_merged_news()
    prices_df = ak.fund_etf_spot_em()

with col1:
    st.subheader("ğŸ”¥ å…¨çƒå®æ—¶æƒ…æŠ¥ (è‡ªåŠ¨åˆ†æ)")
    if not news_df.empty:
        # éå†æ–°é—»
        for i, row in news_df.iterrows():
            # åªè‡ªåŠ¨åˆ†æå‰ 8 æ¡ï¼Œé¿å…é¡µé¢å¡æ­»
            if i < 8: 
                with st.container(border=True):
                    # ç¬¬ä¸€è¡Œï¼šæ¥æº + æ—¶é—´
                    st.markdown(f"**{row['source']} | â° {row['time']}**")
                    st.write(row['content'])
                    
                    # --- AI è‡ªåŠ¨ä»‹å…¥ (æ— éœ€ç‚¹å‡») ---
                    ai_result = analyze_news_automatically(row['content'])
                    
                    # æ ¹æ®åˆ©å¥½/åˆ©ç©º æ”¹å˜èƒŒæ™¯è‰²
                    if "åˆ©å¥½" in ai_result:
                        st.success(f"ğŸ¤– {ai_result}") # ç»¿è‰²/æµ…çº¢èƒŒæ™¯
                    elif "åˆ©ç©º" in ai_result:
                        st.error(f"ğŸ¤– {ai_result}")   # çº¢è‰²/æµ…çº¢èƒŒæ™¯
                    else:
                        st.info(f"ğŸ¤– {ai_result}")    # è“è‰²èƒŒæ™¯
            else:
                # è¶…è¿‡8æ¡çš„åªæ˜¾ç¤ºæ ‡é¢˜ï¼Œä¸ºäº†æ€§èƒ½
                st.caption(f"{row['time']} - {row['content'][:30]}...")
    else:
        st.warning("æš‚æ— æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–åˆ·æ–°")

with col2:
    st.subheader("ğŸ“Š å®æ—¶è¡Œæƒ… (çº¢æ¶¨ç»¿è·Œ)")
    
    my_codes = list(MY_POOL.keys())
    if 'ä»£ç ' in prices_df.columns:
        my_df = prices_df[prices_df['ä»£ç '].isin(my_codes)]
        
        for _, row in my_df.iterrows():
            # --- é¢œè‰²ä¿®æ­£é€»è¾‘ ---
            # Streamlit çš„ "inverse" æ¨¡å¼ä¸‹ï¼šæ­£æ•°(æ¶¨)å˜çº¢ï¼Œè´Ÿæ•°(è·Œ)å˜ç»¿ã€‚
            # è¿™æ­£æ˜¯ A è‚¡è‚¡æ°‘éœ€è¦çš„ã€‚
            st.metric(
                label=f"{row['åç§°']}", 
                value=row['æœ€æ–°ä»·'], 
                delta=f"{row['æ¶¨è·Œå¹…']}%",
                delta_color="inverse" # å…³é”®è®¾ç½®ï¼šçº¢æ¶¨ç»¿è·Œ
            )
            st.divider()
